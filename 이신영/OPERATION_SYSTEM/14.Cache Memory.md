## 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.  

![image](https://github.com/user-attachments/assets/5a37a09a-1542-40a3-90fd-8f9b3ca1a742)


캐시 메모리는 CPU와 메인 메모리(RAM) 사이에 위치하며, 데이터 접근 속도를 향상시키기 위해 사용하는 고속 메모리다.  
메모리 계층성은 속도와 용량의 균형을 위해 설계된 계층적 구조로, CPU 레지스터, 캐시 메모리(L1, L2, L3), 메인 메모리, 디스크(SSD/HDD) 순으로 이루어진다.  


- **속도**: 상위 계층(레지스터, 캐시)일수록 빠르다.  
- **용량**: 하위 계층(메인 메모리, 디스크)일수록 크다.  
- **비용**: 상위 계층일수록 단가가 높다.

## 캐시 메모리는 어디에 위치해 있나요?  
캐시 메모리는 CPU 내부 또는 CPU와 메인 메모리(주기억장치) 사이에 위치한다.  
L1, L2 캐시는 CPU 내부에, L3 캐시는 CPU 내부 또는 외부에 위치한다.  
![image](https://github.com/user-attachments/assets/7ce4fd28-3d53-4597-bc06-634e08450d6c)


## L1, L2 캐시에 대해 설명해 주세요.
여기서 L은 Level을 의미

- **L1 캐시**:  
  - CPU 코어에 가장 가까운 캐시로, 속도가 가장 빠르고 용량이 가장 작다.  
  - 일반적으로 32KB~128KB 정도의 크기를 가지며, 명령어와 데이터를 별도로 저장하는 구조로 나뉘는 경우가 많다.  

- **L2 캐시**:  
  - L1 캐시보다 크며, 비교적 느리지만 여전히 매우 빠르다.  
  - 용량은 일반적으로 수백 KB에서 수 MB 수준이다.  
  - L1 캐시와 CPU 코어 사이의 데이터를 관리하며, 여러 코어가 공유하지 않고 독립적으로 사용한다.

캐시 메모리 용량에 따른 성능 차이는 벤치마크 툴로 테스트할 때 수치로 증명될 뿐이지, 실제로 일반적으로 사용하면서 체감할 수 있을 정도는 아니라고 한다.

## 캐시에 올라오는 데이터는 어떻게 관리되나요?  
캐시에 올라오는 데이터는 **블록 단위**로 관리된다.

- **캐시 라인**: 캐시 메모리는 고정된 크기의 데이터 블록(캐시 라인) 단위로 데이터를 저장한다.  
- **캐시 정책**:  
  - **Write-through**: 데이터 변경 시 메모리와 캐시에 동시에 기록한다.  
  - **Write-back**: 데이터 변경 시 캐시에만 기록하고, 메모리에 반영은 나중에 한다.  
- **교체 알고리즘**: 새로운 데이터를 저장할 공간이 부족할 때, 기존 데이터를 교체하기 위한 알고리즘을 사용한다. 대표적으로 LRU(Least Recently Used), FIFO(First In First Out) 등이 있다.


## 캐시간의 동기화는 어떻게 이루어지나요?  
CPU 캐시와 메인 메모리 간 데이터 일관성을 유지하기 위해 이루어진다. 

### 캐시 기법들
- **Write-through**: 데이터 변경 시 메인 메모리에도 즉시 반영해 일관성을 유지한다.  
- **Write-back**: 변경된 데이터를 캐시에만 저장하고, 메모리 동기화는 나중에 필요할 때 수행한다.  
- **캐시 코히어런시**: 멀티코어 환경에서 동일 데이터의 복사본을 가진 캐시들이 일관성을 유지하기 위해 MESI(Modified, Exclusive, Shared, Invalid) 프로토콜과 같은 기법을 사용한다.


## 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.  
캐시 메모리의 Mapping 방식은 메모리 데이터를 캐시에 저장하기 위한 규칙을 정의한다.
- **Direct Mapping**:  
  - 메모리 블록이 특정 캐시 라인에 고정적으로 매핑된다.  
  - 구현이 간단하고 빠르지만 충돌이 발생할 가능성이 크다.  

- **Fully Associative Mapping**:  
  - 메모리 블록이 캐시의 어느 라인에나 저장될 수 있다.  
  - 유연성이 높지만 매핑 과정에서 비교 연산 비용이 증가한다.  

- **Set Associative Mapping**:  
  - 캐시를 여러 개의 집합(Set)으로 나누고, 각 집합 내에서 Fully Associative 방식을 적용한다.
  - Direct Mapping과 Fully Associative Mapping의 절충안으로, 성능과 구현 복잡도의 균형을 맞춘 방식


## 캐시의 지역성에 대해 설명해 주세요.  
캐시의 지역성은 프로그램이 데이터에 접근하는 패턴을 기반으로, 특정 데이터가 캐시에 존재할 가능성을 높이는 특성을 의미한다.  
- **시간 지역성**: 최근에 접근한 데이터는 가까운 미래에 다시 접근될 가능성이 높다.  
- **공간 지역성**: 접근한 데이터와 가까운 주소의 데이터가 곧 접근될 가능성이 높다.


## 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.  
이차원 배열에서 가로 탐색은 캐시의 공간 지역성을 활용하므로 성능이 더 좋다.  
- **가로 탐색**: 메모리에 연속적으로 저장된 데이터에 접근하므로, 캐시 라인 히트율이 높다.  
- **세로 탐색**: 메모리에서 비연속적인 주소에 접근하므로, 캐시 미스가 발생할 가능성이 크다.


## 캐시의 공간 지역성은 어떻게 구현될 수 있을까요?  
캐시의 공간 지역성은 데이터를 **캐시 라인 단위**로 관리함으로써 구현된다.  
- 캐시는 메모리에서 데이터를 가져올 때, 단일 값이 아닌 인접한 데이터 블록(캐시 라인)을 한 번에 로드한다.  
- 예를 들어, 한 번의 메모리 접근으로 64바이트 크기의 데이터 블록이 캐시에 저장된다.  
- 이를 통해 연속적인 데이터 접근에서 캐시 히트율을 높일 수 있다.
